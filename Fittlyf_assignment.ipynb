{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1110b63",
   "metadata": {},
   "source": [
    "# FUNNEL SHEET ANSWERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cb1e81",
   "metadata": {},
   "source": [
    "## Our objective is to increase the LV5/LV1 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c24ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the basic required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ef011ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read our dataset \n",
    "df = pd.read_csv('fittlyf_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d652e43a",
   "metadata": {},
   "source": [
    "### Now try to explore the dataset and see what our dataset tells us"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046252ad",
   "metadata": {},
   "source": [
    "### EDA and Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4bdd260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d65db5",
   "metadata": {},
   "source": [
    "We had **144** rows and **6** columns in our dataset, we can say it is small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cae390b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Months (Date)</th>\n",
       "      <th>Date</th>\n",
       "      <th>Variants</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>Sum of Clicks</th>\n",
       "      <th>Sum of Visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mar</td>\n",
       "      <td>2023/03/29</td>\n",
       "      <td>Control</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>31312</td>\n",
       "      <td>298032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mar</td>\n",
       "      <td>2023/03/29</td>\n",
       "      <td>Control</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>18399</td>\n",
       "      <td>192144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mar</td>\n",
       "      <td>2023/03/29</td>\n",
       "      <td>Control</td>\n",
       "      <td>Others</td>\n",
       "      <td>34</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mar</td>\n",
       "      <td>2023/03/29</td>\n",
       "      <td>Control</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>660</td>\n",
       "      <td>7646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mar</td>\n",
       "      <td>2023/03/29</td>\n",
       "      <td>Treatment</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>10067</td>\n",
       "      <td>32737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Months (Date)        Date   Variants DeviceType  Sum of Clicks  \\\n",
       "0           Mar  2023/03/29    Control    Desktop          31312   \n",
       "1           Mar  2023/03/29    Control     Mobile          18399   \n",
       "2           Mar  2023/03/29    Control     Others             34   \n",
       "3           Mar  2023/03/29    Control     Tablet            660   \n",
       "4           Mar  2023/03/29  Treatment    Desktop          10067   \n",
       "\n",
       "   Sum of Visitors  \n",
       "0           298032  \n",
       "1           192144  \n",
       "2              375  \n",
       "3             7646  \n",
       "4            32737  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just see how our dataset looks like\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ede9708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144 entries, 0 to 143\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Months (Date)    144 non-null    object\n",
      " 1   Date             144 non-null    object\n",
      " 2   Variants         144 non-null    object\n",
      " 3   DeviceType       144 non-null    object\n",
      " 4   Sum of Clicks    144 non-null    int64 \n",
      " 5   Sum of Visitors  144 non-null    int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 6.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bf0ebd",
   "metadata": {},
   "source": [
    "We can see there are **144** rows of every column is non-null.<br>\n",
    "So,we can say there are **no missing values**, no need to handle the missing data. <br>\n",
    "We can also observe here there are **4 categorical columns** and **2 numerical columns**<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97b1d58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sum of Clicks</th>\n",
       "      <th>Sum of Visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6961.159722</td>\n",
       "      <td>60134.881944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9533.789003</td>\n",
       "      <td>93239.709621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>83.250000</td>\n",
       "      <td>574.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1488.000000</td>\n",
       "      <td>9188.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11253.500000</td>\n",
       "      <td>58703.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34476.000000</td>\n",
       "      <td>313539.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sum of Clicks  Sum of Visitors\n",
       "count     144.000000       144.000000\n",
       "mean     6961.159722     60134.881944\n",
       "std      9533.789003     93239.709621\n",
       "min         1.000000        23.000000\n",
       "25%        83.250000       574.250000\n",
       "50%      1488.000000      9188.500000\n",
       "75%     11253.500000     58703.750000\n",
       "max     34476.000000    313539.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check some statistics of the numerical data we have.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0e8e93",
   "metadata": {},
   "source": [
    "#### To check missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83510807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Months (Date)      0\n",
       "Date               0\n",
       "Variants           0\n",
       "DeviceType         0\n",
       "Sum of Clicks      0\n",
       "Sum of Visitors    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c6e5be",
   "metadata": {},
   "source": [
    "No missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03f7b37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Control      72\n",
       "Treatment    72\n",
       "Name: Variants, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check different unique values of variants with their frequency.\n",
    "df.Variants.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66444526",
   "metadata": {},
   "source": [
    "We can see that **control** and **treatment** have both same weightage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2f5965f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Desktop    36\n",
       "Mobile     36\n",
       "Others     36\n",
       "Tablet     36\n",
       "Name: DeviceType, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check different unique values of DeviceType with their frequency.\n",
    "df.DeviceType.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97f89df",
   "metadata": {},
   "source": [
    "One thing I can observe in dataset, mostly uniques values are divided **equally.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b805f9cd",
   "metadata": {},
   "source": [
    "Now we will see when does **sum of clicks** is high like when the variant is in **control state** or **treatment state**. <br>\n",
    "We compare it by average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e999abc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Clicks - Control: 11100.513888888889\n",
      "Average Clicks - Treatment: 2821.8055555555557\n"
     ]
    }
   ],
   "source": [
    "# Calculate average sum of clicks for Control and Treatment\n",
    "average_clicks_control = df[df['Variants'] == 'Control']['Sum of Clicks'].mean()\n",
    "average_clicks_treatment = df[df['Variants'] == 'Treatment']['Sum of Clicks'].mean()\n",
    "\n",
    "print(f'Average Clicks - Control: {average_clicks_control}')\n",
    "print(f'Average Clicks - Treatment: {average_clicks_treatment}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3dd3f6",
   "metadata": {},
   "source": [
    "We can observe that when it is **control state**, tendenct to click is **high**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4b0373",
   "metadata": {},
   "source": [
    "Similarly we will do for **sum of visitors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "079048c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Visitors - Control: 108312.375\n",
      "Average Visitors - Treatment: 11957.388888888889\n"
     ]
    }
   ],
   "source": [
    "# Calculate average sum of visitors for Control and Treatment\n",
    "average_visitors_control = df[df['Variants'] == 'Control']['Sum of Visitors'].mean()\n",
    "average_visitors_treatment = df[df['Variants'] == 'Treatment']['Sum of Visitors'].mean()\n",
    "\n",
    "print(f'Average Visitors - Control: {average_visitors_control}')\n",
    "print(f'Average Visitors - Treatment: {average_visitors_treatment}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5370ab8d",
   "metadata": {},
   "source": [
    "We can come to conclusion that when it is in **control state**, high chances of visitors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b6b312",
   "metadata": {},
   "source": [
    "Once we will look at **time** related cols also. like **month and date**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17cb7541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apr    120\n",
      "Mar     24\n",
      "Name: Months (Date), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check unique values of 'Months (Date)' with their frequency\n",
    "unique_months_frequency = df['Months (Date)'].value_counts()\n",
    "\n",
    "# Print the result\n",
    "print(unique_months_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265ae489",
   "metadata": {},
   "source": [
    "Mostly this data is taken or under observation in **April** month."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cc01d4",
   "metadata": {},
   "source": [
    "**EDA Completed**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408d2f15",
   "metadata": {},
   "source": [
    "## Question (1): Look at the data and replace the blank values in the ‘value’ column with logical values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fd720c",
   "metadata": {},
   "source": [
    "From above **EDA** part only, we can say we don't have any missing values, so don't need to handle them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3669b83",
   "metadata": {},
   "source": [
    "## Question (2): Create a function which takes region, Customer segment, Start Year & Month, End year & month as an input parameter and gives the following as an output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ac0c5",
   "metadata": {},
   "source": [
    "#### 2(a): A line graph & a bar graph to show the trend of KPIs column for the given date range (i.e., between the Start Year & Month and End year & month). The graph should have appropriate labels, titles and other factors which would make it readable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45f11cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fead7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kpis_trend(region, start_year, start_month, end_year, end_month):\n",
    "    # Extract start and end dates\n",
    "    start_date = f\"{start_year}/{start_month}/01\"\n",
    "    end_date = f\"{end_year}/{end_month}/31\"\n",
    "\n",
    "    # Filter the data based on the 'Months (Date)' column\n",
    "    filtered_data = df[(df['Months (Date)'] >= start_date) & (df['Months (Date)'] <= end_date) & (df['DeviceType'] == region)]\n",
    "\n",
    "    # Check if filtered_data is not empty\n",
    "    if not filtered_data.empty:\n",
    "        # Plotting\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Line Graph\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.lineplot(x='Months (Date)', y='Sum of Clicks', hue='Variants', data=filtered_data, marker='o')\n",
    "        plt.title('Trend of Clicks Over Time')\n",
    "        plt.xlabel('Months (Date)')\n",
    "        plt.ylabel('Sum of Clicks')\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "        # Bar Graph\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.barplot(x='Months (Date)', y='Sum of Visitors', hue='Variants', data=filtered_data)\n",
    "        plt.title('Bar Chart of Visitors Over Time')\n",
    "        plt.xlabel('Months (Date)')\n",
    "        plt.ylabel('Sum of Visitors')\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('No data available for the specified filters.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc58ac5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data available for the specified filters.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "plot_kpis_trend(region='Desktop', start_year='2023', start_month='03', end_year='2023', end_month='04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54b681fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data available for the specified filters.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "plot_kpis_trend(region='Mobile', start_year='2023', start_month='04', end_year='2023', end_month='04')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac918df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data available for the specified filters.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "plot_kpis_trend(region='Desktop', start_year='2023', start_month='04', end_year='2023', end_month='04')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f598825",
   "metadata": {},
   "source": [
    "#### 2(b) :Based on the input parameters, forecasts the Value column using the following algorithm and spit out the actual values and the forecasted values appended in a single csv file for each algorithm:<br>  i.\tSARIMA <br>ii.\tLong Short-Term Memory (LSTM) Networks<br>iii.\tMoving average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1bae8c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (0.14.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from statsmodels) (1.10.1)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.57.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\wasleyaar\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib seaborn statsmodels tensorflow scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23b1e00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34768077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_and_save(region, start_year, start_month, end_year, end_month):\n",
    "    # Extract start and end dates\n",
    "    start_date = f\"{start_year}/{start_month}/01\"\n",
    "    end_date = f\"{end_year}/{end_month}/31\"\n",
    "\n",
    "    # Filter the data based on the 'Months (Date)' column\n",
    "    filtered_data = df[(df['Months (Date)'] >= start_date) & (df['Months (Date)'] <= end_date) & (df['DeviceType'] == region)]\n",
    "\n",
    "    # Check if filtered_data is not empty\n",
    "    if not filtered_data.empty:\n",
    "        # Extract relevant columns\n",
    "        time_series_data = filtered_data[['Months (Date)', 'Sum of Visitors']].rename(columns={'Months (Date)': 'Date', 'Sum of Visitors': 'Value'})\n",
    "\n",
    "        # Save the original time series data to a CSV file\n",
    "        time_series_data.to_csv('original_data.csv', index=False)\n",
    "\n",
    "        # Forecast using SARIMA\n",
    "        sarima_forecast = forecast_sarima(time_series_data)\n",
    "\n",
    "        # Forecast using LSTM\n",
    "        lstm_forecast = forecast_lstm(time_series_data)\n",
    "\n",
    "        # Forecast using Moving Average\n",
    "        ma_forecast = forecast_moving_average(time_series_data)\n",
    "\n",
    "        # Combine the forecasts into a single DataFrame\n",
    "        combined_forecasts = pd.DataFrame({\n",
    "            'Date': time_series_data['Date'],\n",
    "            'SARIMA Forecast': sarima_forecast,\n",
    "            'LSTM Forecast': lstm_forecast,\n",
    "            'Moving Average Forecast': ma_forecast\n",
    "        })\n",
    "\n",
    "        # Save the combined forecasts to a CSV file\n",
    "        combined_forecasts.to_csv('combined_forecasts.csv', index=False)\n",
    "    else:\n",
    "        print('No data available for the specified filters.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f264db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_sarima(time_series_data):\n",
    "    # SARIMA model\n",
    "    model = SARIMAX(time_series_data['Value'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12), enforce_stationarity=False)\n",
    "    sarima_fit = model.fit(disp=False)\n",
    "    sarima_forecast = sarima_fit.get_forecast(steps=len(time_series_data)).predicted_mean\n",
    "    return sarima_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "131db337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_lstm(time_series_data):\n",
    "    # Normalize data for LSTM\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(time_series_data['Value'].values.reshape(-1, 1))\n",
    "\n",
    "    # Prepare data for LSTM\n",
    "    x_train, y_train = create_lstm_dataset(scaled_data, time_steps=3)\n",
    "    \n",
    "    # Build LSTM model\n",
    "    lstm_model = build_lstm_model(x_train.shape[1])\n",
    "\n",
    "    # Train LSTM model\n",
    "    lstm_model.fit(x_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    # Make predictions\n",
    "    lstm_forecast = predict_lstm_forecast(lstm_model, scaled_data)\n",
    "\n",
    "    # Inverse transform the forecasted values\n",
    "    lstm_forecast = scaler.inverse_transform(lstm_forecast.reshape(-1, 1)).flatten()\n",
    "\n",
    "    return lstm_forecast\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d7236df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_moving_average(time_series_data):\n",
    "    # Moving average forecast\n",
    "    ma_forecast = time_series_data['Value'].rolling(window=3).mean()\n",
    "    ma_forecast = ma_forecast.fillna(0)  # Filling NaN values with 0 for simplicity\n",
    "    return ma_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b90aff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_dataset(data, time_steps=1):\n",
    "    x, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        a = data[i:(i + time_steps), 0]\n",
    "        x.append(a)\n",
    "        y.append(data[i + time_steps, 0])\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "079e74d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(input_shape, 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9be536e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lstm_forecast(model, data):\n",
    "    x_test = create_lstm_dataset(data, time_steps=3)[0]\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "    lstm_forecast = model.predict(x_test)\n",
    "    return lstm_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f08046f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data available for the specified filters.\n"
     ]
    }
   ],
   "source": [
    " #Example usage:\n",
    "forecast_and_save(region='Desktop', start_year='2023', start_month='04', end_year='2023', end_month='04')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e61c3b3",
   "metadata": {},
   "source": [
    "#### 2(c) : From the csv created above find out which algorithm best predicted the values for the input parameters. The function should also create a summary table for the forecast where we could see the accuracy of the time series forecasting model. You may add more evaluating criteria, but the following are a must have:<br> i.\tMean Absolute Percentage Error (MAPE)<br>ii.\tMean Squared Error (MSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78a543d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ab6f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_forecasts(file_path):\n",
    "    # Read the combined forecasts from the CSV file\n",
    "    combined_forecasts = pd.read_csv(file_path)\n",
    "\n",
    "    # Evaluate SARIMA forecast\n",
    "    sarima_mape = calculate_mape(combined_forecasts['Value'], combined_forecasts['SARIMA Forecast'])\n",
    "    sarima_mse = mean_squared_error(combined_forecasts['Value'], combined_forecasts['SARIMA Forecast'])\n",
    "\n",
    "    # Evaluate LSTM forecast\n",
    "    lstm_mape = calculate_mape(combined_forecasts['Value'], combined_forecasts['LSTM Forecast'])\n",
    "    lstm_mse = mean_squared_error(combined_forecasts['Value'], combined_forecasts['LSTM Forecast'])\n",
    "\n",
    "    # Evaluate Moving Average forecast\n",
    "    ma_mape = calculate_mape(combined_forecasts['Value'], combined_forecasts['Moving Average Forecast'])\n",
    "    ma_mse = mean_squared_error(combined_forecasts['Value'], combined_forecasts['Moving Average Forecast'])\n",
    "\n",
    "    # Create a summary table\n",
    "    summary_table = pd.DataFrame({\n",
    "        'Model': ['SARIMA', 'LSTM', 'Moving Average'],\n",
    "        'MAPE': [sarima_mape, lstm_mape, ma_mape],\n",
    "        'MSE': [sarima_mse, lstm_mse, ma_mse]\n",
    "    })\n",
    "\n",
    "    print(\"Summary Table:\")\n",
    "    print(summary_table)\n",
    "\n",
    "def calculate_mape(actual, forecast):\n",
    "    return np.mean(np.abs((actual - forecast) / actual)) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c627729",
   "metadata": {},
   "source": [
    "# AB_Test Sheet questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de38e4c0",
   "metadata": {},
   "source": [
    "#### Q1) a.Have we reached the required amount of sample size to conclude the test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed363e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required Sample Size: 1771.23\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Given parameters\n",
    "MDE = 0.03  # 3%\n",
    "alpha = 0.05  # Significance level\n",
    "power = 0.8  # Statistical power\n",
    "\n",
    "# Baseline conversion rate (p1)\n",
    "baseline_conversion = 0.1  # Replace with the actual baseline conversion rate\n",
    "\n",
    "# Expected conversion rate with treatment (p2)\n",
    "expected_conversion = baseline_conversion + MDE\n",
    "\n",
    "# Z-score for the specified significance level (α/2)\n",
    "z_alpha_2 = stats.norm.ppf(1 - alpha/2)\n",
    "\n",
    "# Z-score for the specified statistical power (1−β)\n",
    "z_beta = stats.norm.ppf(power)\n",
    "\n",
    "# Calculate sample size\n",
    "sample_size = ((z_alpha_2 + z_beta)**2 * (baseline_conversion * (1 - baseline_conversion) + expected_conversion * (1 - expected_conversion))) / ((baseline_conversion - expected_conversion)**2)\n",
    "\n",
    "print(f\"Required Sample Size: {sample_size:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac809918",
   "metadata": {},
   "source": [
    "### No, we have not reached the sample size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f12a63",
   "metadata": {},
   "source": [
    "#### (b): 2.\tAt 95% confidence can you tell us <br> a.\tHas the test reached statistical significance?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7c42725",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ab_test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mstats\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming your DataFrame is named 'ab_test_data'\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Replace this with the actual name of your DataFrame\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Extract the control and treatment groups from your DataFrame\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m control_group \u001b[38;5;241m=\u001b[39m ab_test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mControl\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      9\u001b[0m treatment_group \u001b[38;5;241m=\u001b[39m ab_test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTreatment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Calculate the p-value using a two-sample t-test\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ab_test_data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Assuming your DataFrame is named 'ab_test_data'\n",
    "# Replace this with the actual name of your DataFrame\n",
    "\n",
    "# Extract the control and treatment groups from your DataFrame\n",
    "control_group = ab_test_data['Control'].tolist()\n",
    "treatment_group = ab_test_data['Treatment'].tolist()\n",
    "\n",
    "# Calculate the p-value using a two-sample t-test\n",
    "t_stat, p_value = stats.ttest_ind(control_group, treatment_group)\n",
    "\n",
    "# Set the significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Check for statistical significance\n",
    "if p_value < alpha:\n",
    "    print(f\"The test is statistically significant at {100 * (1 - alpha):.2f}% confidence.\")\n",
    "else:\n",
    "    print(f\"The test is not statistically significant at {100 * (1 - alpha):.2f}% confidence.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77edfee6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
